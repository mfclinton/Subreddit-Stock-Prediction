{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fc693ea-e7af-4ef2-9614-ff0eb4124352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from collections import Counter\n",
    "import jsonlines\n",
    "path = r'../../data/' # use your path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b813f8f-248c-4dae-ac82-78e4c5f744a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open( \"tickDict.p\", \"rb\") as f:\n",
    "    tickDict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad8ae88f-e3ad-43c4-a4b2-6a13a62584b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_tickers = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8306eee7-0b8b-4e91-bb62-4071cda59698",
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklist = {'I', 'ARE',  'ON', 'GO', 'NOW', 'CAN', 'UK', 'SO', 'OR', 'OUT', 'SEE', 'ONE', 'LOVE', 'U', 'STAY', 'HAS', 'BY', 'BIG', 'GOOD', 'RIDE', 'EOD', 'ELON', 'WSB', 'THE', 'A', 'ROPE', 'YOLO', 'TOS', 'CEO', 'DD', 'IT', 'OPEN', 'ATH', 'PM', 'IRS', 'FOR','DEC', 'BE', 'IMO', 'ALL', 'RH', 'EV', 'TOS', 'CFO', 'CTO', 'DD', 'BTFD', 'WSB', 'OK', 'PDT', 'RH', 'KYS', 'FD', 'TYS', 'US', 'USA', 'IT', 'ATH', 'RIP', 'BMW', 'GDP', 'OTM', 'ATM', 'ITM', 'IMO', 'LOL', 'AM', 'BE', 'PR', 'PRAY', 'PT', 'FBI', 'SEC', 'GOD', 'NOT', 'POS', 'FOMO', 'TL;DR', 'EDIT', 'STILL', 'WTF', 'RAW', 'PM', 'LMAO', 'LMFAO', 'ROFL', 'EZ', 'RED', 'BEZOS', 'TICK', 'IS', 'PM', 'LPT', 'GOAT', 'FL', 'CA', 'IL', 'MACD', 'HQ', 'OP', 'PS', 'AH', 'TL', 'JAN', 'FEB', 'JUL', 'AUG', 'SEP', 'SEPT', 'OCT', 'NOV', 'FDA', 'IV', 'ER', 'IPO', 'MILF', 'BUT', 'SSN', 'FIFA', 'USD', 'CPU', 'AT', 'GG', 'Mar'}\n",
    "ticks = set(pd.read_csv(path + 'ExchangeListings/tickers.csv', index_col=None, header=0)['Symbol'])\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0420d193-2c99-4f73-9e4f-c3bd68cb9749",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:00, 50.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data\\daytrading_submission.csv\n",
      "../../data\\daytrading_submission.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6535it [02:12, 49.50it/s]\n",
      "8it [00:00, 76.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data\\dividends_submission.csv\n",
      "../../data\\dividends_submission.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2298it [00:45, 51.00it/s]\n",
      "6it [00:00, 57.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data\\economy_submission.csv\n",
      "../../data\\economy_submission.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2134it [00:49, 43.49it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data\\globalmarkets_submission.csv\n",
      "../../data\\globalmarkets_submission.jsonl\n",
      "../../data\\investing_submission.csv\n",
      "../../data\\investing_submission.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "53801it [17:35, 50.97it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data\\options_submission.csv\n",
      "../../data\\options_submission.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14056it [04:49, 48.48it/s]\n",
      "1it [00:00,  9.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data\\securityanalysis_submission.csv\n",
      "../../data\\securityanalysis_submission.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3142it [01:30, 34.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data\\stockmarket_submission.csv\n",
      "../../data\\stockmarket_submission.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13136it [07:42, 28.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data\\stocks_submission.csv\n",
      "../../data\\stocks_submission.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48914it [16:44, 48.68it/s]\n"
     ]
    }
   ],
   "source": [
    "all_submission_files = glob.glob(path + \"*_submission.csv\")\n",
    "\n",
    "for filename in all_submission_files:\n",
    "    print(filename)\n",
    "    new_fn = filename[:-3] + 'jsonl'\n",
    "    print(new_fn)\n",
    "    new_rows = []\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    for _, row in tqdm(df.iterrows()):\n",
    "        new_row = row.to_dict()\n",
    "        tickCnt = Counter()\n",
    "        text = f\"{row['title']}\\n{row['text']}\"\n",
    "        split = str(text).split(\" \")\n",
    "        for word in split:\n",
    "            word = word.replace(\"$\", \"\")        \n",
    "            # upper = ticker, length of ticker <= 5, excluded words,                     \n",
    "            if word.isupper() and len(word) <= 5 and word not in blacklist and word in ticks:\n",
    "                seen_tickers.add(word)\n",
    "                tickCnt[word] += 1\n",
    "        doc = nlp(text)\n",
    "        for e in doc.ents:\n",
    "            if e.label_ == \"ORG\" and e.text in tickDict and e.text not in ticks:\n",
    "                tick = tickDict[e.text]\n",
    "                seen_tickers.add(tick)\n",
    "                tickCnt[tick] += 1\n",
    "        new_row['tickers'] = tickCnt.most_common()\n",
    "        new_rows.append(new_row)\n",
    "    with jsonlines.open(new_fn, mode='w') as writer:\n",
    "        writer.write_all(new_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1e22a2c-fcc1-4cc0-8a80-126959785723",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open( \"seen.p\", \"wb\") as f:\n",
    "    pickle.dump(seen_tickers, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f199d39-98b5-4a72-8ade-bf647f36e18e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4461"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seen_tickers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
