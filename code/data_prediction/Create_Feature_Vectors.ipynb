{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "operating-vacation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import pandas_datareader as dr\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import glob\n",
    "from collections import Counter\n",
    "from ast import literal_eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "formal-bulletin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mfclinton/Documents/Repos/Subreddit-Stock-Prediction\n"
     ]
    }
   ],
   "source": [
    "os.chdir('..')\n",
    "os.chdir('..')\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "expensive-cradle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/stockmarket_comments.jsonl\n",
      "data/options_comments.jsonl\n",
      "data/investing_comments.jsonl\n",
      "data/stocks_submission.jsonl\n",
      "data/securityanalysis_comments.jsonl\n",
      "data/stockmarket_submission.jsonl\n",
      "data/options_submission.jsonl\n",
      "data/daytrading_submission.jsonl\n",
      "data/daytrading_comments.jsonl\n",
      "data/economy_submission.jsonl\n",
      "data/stocks_comments.jsonl\n",
      "data/dividends_submission.jsonl\n",
      "data/investing_submission.jsonl\n",
      "data/dividends_comments.jsonl\n",
      "data/securityanalysis_submission.jsonl\n",
      "data/economy_comments.jsonl\n"
     ]
    }
   ],
   "source": [
    "path = r'data' # use your path\n",
    "all_files = glob.glob(path + \"/*.jsonl\")\n",
    "\n",
    "tickCnt2 = Counter()\n",
    "\n",
    "for filename in all_files:\n",
    "    print(filename)\n",
    "    df = pd.read_json(filename,lines=True)\n",
    "    for x in df['tickers']:\n",
    "        if len(x) > 0:\n",
    "            y, z = x[0]\n",
    "            tickCnt2[y] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "distant-edwards",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('TSLA', 3382), ('AMD', 2875), ('AAPL', 2140), ('AMZN', 1981), ('MSFT', 1670), ('TD', 1597), ('GOOG', 1543), ('NIO', 1299), ('GE', 1281), ('FB', 1178), ('BABA', 1048)]\n"
     ]
    }
   ],
   "source": [
    "top_n = 11\n",
    "top_list = tickCnt2.most_common(top_n)\n",
    "print(top_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "facial-basket",
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklist = [\"TD\"]\n",
    "top_list = list(filter(lambda ticker_and_count: ticker_and_count[0] not in blacklist, top_list))\n",
    "ticker_list = list(map(lambda t_a_c: t_a_c[0], top_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "electrical-mambo",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime(2014,1,1)\n",
    "end = datetime(2021,1,1)\n",
    "\n",
    "stock_data = {}\n",
    "for ticker in ticker_list:\n",
    "    stock = dr.data.DataReader(ticker, data_source='yahoo', start=start, end=end)\n",
    "    stock_data[ticker] = stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "prime-healthcare",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>submission_name</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>tickers</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>t3_a4et2x</td>\n",
       "      <td>ebe85cf</td>\n",
       "      <td>Does anyone have a excel sample sheet they can...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.544318e+09</td>\n",
       "      <td>[[GOOG, 1]]</td>\n",
       "      <td>0.054193</td>\n",
       "      <td>0.913546</td>\n",
       "      <td>0.032261</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>t3_an4n5g</td>\n",
       "      <td>efqslh9</td>\n",
       "      <td>Define cheap. For me I'm putting a bunch of mo...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.549309e+09</td>\n",
       "      <td>[[MSFT, 1]]</td>\n",
       "      <td>0.016944</td>\n",
       "      <td>0.317534</td>\n",
       "      <td>0.665522</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>t3_bdmdvj</td>\n",
       "      <td>elfucsc</td>\n",
       "      <td>I am thinking about doing this strategy as wel...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.555871e+09</td>\n",
       "      <td>[[FB, 1]]</td>\n",
       "      <td>0.023970</td>\n",
       "      <td>0.929311</td>\n",
       "      <td>0.046719</td>\n",
       "      <td>FB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>t3_cknban</td>\n",
       "      <td>evsth5n</td>\n",
       "      <td>MSFT TJX COST ADP APD HD AFL UNH VFC MKC</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.564756e+09</td>\n",
       "      <td>[[MSFT, 1], [TJX, 1], [COST, 1], [ADP, 1], [AP...</td>\n",
       "      <td>0.019561</td>\n",
       "      <td>0.930602</td>\n",
       "      <td>0.049836</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>55</td>\n",
       "      <td>t3_drbtts</td>\n",
       "      <td>f6h752b</td>\n",
       "      <td>MSFT and AAPL both pay dividends. You can set ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.572839e+09</td>\n",
       "      <td>[[MSFT, 1], [AAPL, 1]]</td>\n",
       "      <td>0.017734</td>\n",
       "      <td>0.936916</td>\n",
       "      <td>0.045350</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41596</th>\n",
       "      <td>41596</td>\n",
       "      <td>t3_knnc52</td>\n",
       "      <td>ghm2c5k</td>\n",
       "      <td>Mgmt style difference.\\n\\nYou hear Adobe brag ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.609429e+09</td>\n",
       "      <td>[[MSFT, 1]]</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.924701</td>\n",
       "      <td>0.036005</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41597</th>\n",
       "      <td>41597</td>\n",
       "      <td>t3_knnc52</td>\n",
       "      <td>ghm73op</td>\n",
       "      <td>Azure will provide consistent growth for the n...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.609431e+09</td>\n",
       "      <td>[[MSFT, 2], [AMZN, 1]]</td>\n",
       "      <td>0.011626</td>\n",
       "      <td>0.846059</td>\n",
       "      <td>0.142315</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41598</th>\n",
       "      <td>41598</td>\n",
       "      <td>t3_knnc52</td>\n",
       "      <td>ghndxub</td>\n",
       "      <td>Ask yourself one question \\n\\nIs Microsoft off...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.609454e+09</td>\n",
       "      <td>[[MSFT, 1]]</td>\n",
       "      <td>0.014535</td>\n",
       "      <td>0.902674</td>\n",
       "      <td>0.082791</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41599</th>\n",
       "      <td>41599</td>\n",
       "      <td>t3_knnc52</td>\n",
       "      <td>ghlw67q</td>\n",
       "      <td>Tldr: MSFT to the moon ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.609425e+09</td>\n",
       "      <td>[[MSFT, 1]]</td>\n",
       "      <td>0.018985</td>\n",
       "      <td>0.918247</td>\n",
       "      <td>0.062768</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41600</th>\n",
       "      <td>41600</td>\n",
       "      <td>t3_knjs1t</td>\n",
       "      <td>ghkwxe8</td>\n",
       "      <td>Itâ€™s not a battery day. Itâ€™s just NIO day. The...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.609393e+09</td>\n",
       "      <td>[[NIO, 1]]</td>\n",
       "      <td>0.057290</td>\n",
       "      <td>0.912919</td>\n",
       "      <td>0.029791</td>\n",
       "      <td>NIO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11161 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0 submission_name       id  \\\n",
       "1               1       t3_a4et2x  ebe85cf   \n",
       "6               6       t3_an4n5g  efqslh9   \n",
       "19             19       t3_bdmdvj  elfucsc   \n",
       "37             37       t3_cknban  evsth5n   \n",
       "55             55       t3_drbtts  f6h752b   \n",
       "...           ...             ...      ...   \n",
       "41596       41596       t3_knnc52  ghm2c5k   \n",
       "41597       41597       t3_knnc52  ghm73op   \n",
       "41598       41598       t3_knnc52  ghndxub   \n",
       "41599       41599       t3_knnc52  ghlw67q   \n",
       "41600       41600       t3_knjs1t  ghkwxe8   \n",
       "\n",
       "                                                    text  score   created_utc  \\\n",
       "1      Does anyone have a excel sample sheet they can...    3.0  1.544318e+09   \n",
       "6      Define cheap. For me I'm putting a bunch of mo...    3.0  1.549309e+09   \n",
       "19     I am thinking about doing this strategy as wel...    2.0  1.555871e+09   \n",
       "37              MSFT TJX COST ADP APD HD AFL UNH VFC MKC    2.0  1.564756e+09   \n",
       "55     MSFT and AAPL both pay dividends. You can set ...    8.0  1.572839e+09   \n",
       "...                                                  ...    ...           ...   \n",
       "41596  Mgmt style difference.\\n\\nYou hear Adobe brag ...    3.0  1.609429e+09   \n",
       "41597  Azure will provide consistent growth for the n...    2.0  1.609431e+09   \n",
       "41598  Ask yourself one question \\n\\nIs Microsoft off...    2.0  1.609454e+09   \n",
       "41599                     Tldr: MSFT to the moon ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€    2.0  1.609425e+09   \n",
       "41600  Itâ€™s not a battery day. Itâ€™s just NIO day. The...    6.0  1.609393e+09   \n",
       "\n",
       "                                                 tickers       neg       neu  \\\n",
       "1                                            [[GOOG, 1]]  0.054193  0.913546   \n",
       "6                                            [[MSFT, 1]]  0.016944  0.317534   \n",
       "19                                             [[FB, 1]]  0.023970  0.929311   \n",
       "37     [[MSFT, 1], [TJX, 1], [COST, 1], [ADP, 1], [AP...  0.019561  0.930602   \n",
       "55                                [[MSFT, 1], [AAPL, 1]]  0.017734  0.936916   \n",
       "...                                                  ...       ...       ...   \n",
       "41596                                        [[MSFT, 1]]  0.039295  0.924701   \n",
       "41597                             [[MSFT, 2], [AMZN, 1]]  0.011626  0.846059   \n",
       "41598                                        [[MSFT, 1]]  0.014535  0.902674   \n",
       "41599                                        [[MSFT, 1]]  0.018985  0.918247   \n",
       "41600                                         [[NIO, 1]]  0.057290  0.912919   \n",
       "\n",
       "            pos ticker  \n",
       "1      0.032261   GOOG  \n",
       "6      0.665522   MSFT  \n",
       "19     0.046719     FB  \n",
       "37     0.049836   MSFT  \n",
       "55     0.045350   MSFT  \n",
       "...         ...    ...  \n",
       "41596  0.036005   MSFT  \n",
       "41597  0.142315   MSFT  \n",
       "41598  0.082791   MSFT  \n",
       "41599  0.062768   MSFT  \n",
       "41600  0.029791    NIO  \n",
       "\n",
       "[11161 rows x 11 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_sentiments = pd.read_csv(\"data/LabelledData/submissions_with_tickers_labelled.csv\")\n",
    "submission_sentiments.set_index(\"name\", inplace=True)\n",
    "comment_sentiments = pd.read_csv(\"data/LabelledData/comments_with_tickers_labelled.csv\")\n",
    "\n",
    "# Get Top\n",
    "comment_sentiments[\"tickers\"] = comment_sentiments[\"tickers\"].apply(lambda x: literal_eval(str(x)))\n",
    "comment_sentiments[\"ticker\"] = comment_sentiments[\"tickers\"].map(lambda tickers: tickers[0][0] if len(tickers) > 0 else np.NaN)\n",
    "# print(ticker_list)\n",
    "comment_sentiments = comment_sentiments[comment_sentiments[\"ticker\"].isin(ticker_list)]\n",
    "comment_sentiments.dropna()\n",
    "# print(comment_sentiments[\"ticker\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "difficult-giant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/stocks_submission.jsonl\n",
      "2014-12-25 00:00:00\n",
      "2014-12-26 00:00:00\n",
      "2014-12-27 00:00:00\n",
      "2014-12-28 00:00:00\n",
      "2014-12-29 00:00:00\n",
      "2014-12-30 00:00:00\n",
      "2014-12-31 00:00:00\n",
      "2015-12-25 00:00:00\n",
      "2015-12-26 00:00:00\n",
      "2015-12-27 00:00:00\n",
      "2015-12-28 00:00:00\n",
      "2015-12-29 00:00:00\n",
      "2015-12-30 00:00:00\n",
      "2015-12-31 00:00:00\n",
      "2016-12-25 00:00:00\n",
      "2016-12-26 00:00:00\n",
      "2016-12-27 00:00:00\n",
      "2016-12-28 00:00:00\n",
      "2016-12-29 00:00:00\n",
      "2016-12-30 00:00:00\n",
      "2016-12-31 00:00:00\n",
      "2017-12-25 00:00:00\n",
      "2017-12-26 00:00:00\n",
      "2017-12-27 00:00:00\n",
      "2017-12-28 00:00:00\n",
      "2017-12-29 00:00:00\n",
      "2017-12-30 00:00:00\n",
      "2017-12-31 00:00:00\n",
      "2018-12-25 00:00:00\n",
      "2018-12-26 00:00:00\n",
      "2018-12-27 00:00:00\n",
      "2018-12-28 00:00:00\n",
      "2018-12-29 00:00:00\n",
      "2018-12-30 00:00:00\n",
      "2018-12-31 00:00:00\n",
      "2019-12-25 00:00:00\n",
      "2019-12-26 00:00:00\n",
      "2019-12-27 00:00:00\n",
      "2019-12-28 00:00:00\n",
      "2019-12-29 00:00:00\n",
      "2019-12-30 00:00:00\n",
      "2019-12-31 00:00:00\n",
      "2020-12-25 00:00:00\n",
      "data/stockmarket_submission.jsonl\n",
      "2014-12-25 00:00:00\n",
      "2014-12-26 00:00:00\n",
      "2014-12-27 00:00:00\n",
      "2014-12-28 00:00:00\n",
      "2014-12-29 00:00:00\n",
      "2014-12-30 00:00:00\n",
      "2014-12-31 00:00:00\n",
      "2015-12-25 00:00:00\n",
      "2015-12-26 00:00:00\n",
      "2015-12-27 00:00:00\n",
      "2015-12-28 00:00:00\n",
      "2015-12-29 00:00:00\n",
      "2015-12-30 00:00:00\n",
      "2015-12-31 00:00:00\n",
      "2016-12-25 00:00:00\n",
      "2016-12-26 00:00:00\n",
      "2016-12-27 00:00:00\n",
      "2016-12-28 00:00:00\n",
      "2016-12-29 00:00:00\n",
      "2016-12-30 00:00:00\n",
      "2016-12-31 00:00:00\n",
      "2017-12-25 00:00:00\n",
      "2017-12-26 00:00:00\n",
      "2017-12-27 00:00:00\n",
      "2017-12-28 00:00:00\n",
      "2017-12-29 00:00:00\n",
      "2017-12-30 00:00:00\n",
      "2017-12-31 00:00:00\n",
      "2018-12-25 00:00:00\n",
      "2018-12-26 00:00:00\n",
      "2018-12-27 00:00:00\n",
      "2018-12-28 00:00:00\n",
      "2018-12-29 00:00:00\n",
      "2018-12-30 00:00:00\n",
      "2018-12-31 00:00:00\n",
      "2019-12-25 00:00:00\n",
      "2019-12-26 00:00:00\n",
      "2019-12-27 00:00:00\n",
      "2019-12-28 00:00:00\n",
      "2019-12-29 00:00:00\n",
      "2019-12-30 00:00:00\n",
      "2019-12-31 00:00:00\n",
      "2020-12-25 00:00:00\n",
      "data/options_submission.jsonl\n",
      "2014-12-25 00:00:00\n",
      "2014-12-26 00:00:00\n",
      "2014-12-27 00:00:00\n",
      "2014-12-28 00:00:00\n",
      "2014-12-29 00:00:00\n",
      "2014-12-30 00:00:00\n",
      "2014-12-31 00:00:00\n",
      "2015-12-25 00:00:00\n",
      "2015-12-26 00:00:00\n",
      "2015-12-27 00:00:00\n",
      "2015-12-28 00:00:00\n",
      "2015-12-29 00:00:00\n",
      "2015-12-30 00:00:00\n",
      "2015-12-31 00:00:00\n",
      "2016-12-25 00:00:00\n",
      "2016-12-26 00:00:00\n",
      "2016-12-27 00:00:00\n",
      "2016-12-28 00:00:00\n",
      "2016-12-29 00:00:00\n",
      "2016-12-30 00:00:00\n",
      "2016-12-31 00:00:00\n",
      "2017-12-25 00:00:00\n",
      "2017-12-26 00:00:00\n",
      "2017-12-27 00:00:00\n",
      "2017-12-28 00:00:00\n",
      "2017-12-29 00:00:00\n",
      "2017-12-30 00:00:00\n",
      "2017-12-31 00:00:00\n",
      "2018-12-25 00:00:00\n",
      "2018-12-26 00:00:00\n",
      "2018-12-27 00:00:00\n",
      "2018-12-28 00:00:00\n",
      "2018-12-29 00:00:00\n",
      "2018-12-30 00:00:00\n",
      "2018-12-31 00:00:00\n",
      "2019-12-25 00:00:00\n",
      "2019-12-26 00:00:00\n",
      "2019-12-27 00:00:00\n",
      "2019-12-28 00:00:00\n",
      "2019-12-29 00:00:00\n",
      "2019-12-30 00:00:00\n",
      "2019-12-31 00:00:00\n",
      "2020-12-25 00:00:00\n",
      "data/daytrading_submission.jsonl\n",
      "2014-12-25 00:00:00\n",
      "2014-12-26 00:00:00\n",
      "2014-12-27 00:00:00\n",
      "2014-12-28 00:00:00\n",
      "2014-12-29 00:00:00\n",
      "2014-12-30 00:00:00\n",
      "2014-12-31 00:00:00\n",
      "2015-12-25 00:00:00\n",
      "2015-12-26 00:00:00\n",
      "2015-12-27 00:00:00\n",
      "2015-12-28 00:00:00\n",
      "2015-12-29 00:00:00\n",
      "2015-12-30 00:00:00\n",
      "2015-12-31 00:00:00\n",
      "2016-12-25 00:00:00\n",
      "2016-12-26 00:00:00\n",
      "2016-12-27 00:00:00\n",
      "2016-12-28 00:00:00\n",
      "2016-12-29 00:00:00\n",
      "2016-12-30 00:00:00\n",
      "2016-12-31 00:00:00\n",
      "2017-12-25 00:00:00\n",
      "2017-12-26 00:00:00\n",
      "2017-12-27 00:00:00\n",
      "2017-12-28 00:00:00\n",
      "2017-12-29 00:00:00\n",
      "2017-12-30 00:00:00\n",
      "2017-12-31 00:00:00\n",
      "2018-12-25 00:00:00\n",
      "2018-12-26 00:00:00\n",
      "2018-12-27 00:00:00\n",
      "2018-12-28 00:00:00\n",
      "2018-12-29 00:00:00\n",
      "2018-12-30 00:00:00\n",
      "2018-12-31 00:00:00\n",
      "2019-12-25 00:00:00\n",
      "2019-12-26 00:00:00\n",
      "2019-12-27 00:00:00\n",
      "2019-12-28 00:00:00\n",
      "2019-12-29 00:00:00\n",
      "2019-12-30 00:00:00\n",
      "2019-12-31 00:00:00\n",
      "2020-12-25 00:00:00\n",
      "data/economy_submission.jsonl\n",
      "2014-12-25 00:00:00\n",
      "2014-12-26 00:00:00\n",
      "2014-12-27 00:00:00\n",
      "2014-12-28 00:00:00\n",
      "2014-12-29 00:00:00\n",
      "2014-12-30 00:00:00\n",
      "2014-12-31 00:00:00\n",
      "2015-12-25 00:00:00\n",
      "2015-12-26 00:00:00\n",
      "2015-12-27 00:00:00\n",
      "2015-12-28 00:00:00\n",
      "2015-12-29 00:00:00\n",
      "2015-12-30 00:00:00\n",
      "2015-12-31 00:00:00\n",
      "2016-12-25 00:00:00\n",
      "2016-12-26 00:00:00\n",
      "2016-12-27 00:00:00\n",
      "2016-12-28 00:00:00\n",
      "2016-12-29 00:00:00\n",
      "2016-12-30 00:00:00\n",
      "2016-12-31 00:00:00\n",
      "2017-12-25 00:00:00\n",
      "2017-12-26 00:00:00\n",
      "2017-12-27 00:00:00\n",
      "2017-12-28 00:00:00\n",
      "2017-12-29 00:00:00\n",
      "2017-12-30 00:00:00\n",
      "2017-12-31 00:00:00\n",
      "2018-12-25 00:00:00\n",
      "2018-12-26 00:00:00\n",
      "2018-12-27 00:00:00\n",
      "2018-12-28 00:00:00\n",
      "2018-12-29 00:00:00\n",
      "2018-12-30 00:00:00\n",
      "2018-12-31 00:00:00\n",
      "2019-12-25 00:00:00\n",
      "2019-12-26 00:00:00\n",
      "2019-12-27 00:00:00\n",
      "2019-12-28 00:00:00\n",
      "2019-12-29 00:00:00\n",
      "2019-12-30 00:00:00\n",
      "2019-12-31 00:00:00\n",
      "2020-12-25 00:00:00\n",
      "data/dividends_submission.jsonl\n",
      "2014-12-25 00:00:00\n",
      "2014-12-26 00:00:00\n",
      "2014-12-27 00:00:00\n",
      "2014-12-28 00:00:00\n",
      "2014-12-29 00:00:00\n",
      "2014-12-30 00:00:00\n",
      "2014-12-31 00:00:00\n",
      "2015-12-25 00:00:00\n",
      "2015-12-26 00:00:00\n",
      "2015-12-27 00:00:00\n",
      "2015-12-28 00:00:00\n",
      "2015-12-29 00:00:00\n",
      "2015-12-30 00:00:00\n",
      "2015-12-31 00:00:00\n",
      "2016-12-25 00:00:00\n",
      "2016-12-26 00:00:00\n",
      "2016-12-27 00:00:00\n",
      "2016-12-28 00:00:00\n",
      "2016-12-29 00:00:00\n",
      "2016-12-30 00:00:00\n",
      "2016-12-31 00:00:00\n",
      "2017-12-25 00:00:00\n",
      "2017-12-26 00:00:00\n",
      "2017-12-27 00:00:00\n",
      "2017-12-28 00:00:00\n",
      "2017-12-29 00:00:00\n",
      "2017-12-30 00:00:00\n",
      "2017-12-31 00:00:00\n",
      "2018-12-25 00:00:00\n",
      "2018-12-26 00:00:00\n",
      "2018-12-27 00:00:00\n",
      "2018-12-28 00:00:00\n",
      "2018-12-29 00:00:00\n",
      "2018-12-30 00:00:00\n",
      "2018-12-31 00:00:00\n",
      "2019-12-25 00:00:00\n",
      "2019-12-26 00:00:00\n",
      "2019-12-27 00:00:00\n",
      "2019-12-28 00:00:00\n",
      "2019-12-29 00:00:00\n",
      "2019-12-30 00:00:00\n",
      "2019-12-31 00:00:00\n",
      "2020-12-25 00:00:00\n",
      "data/investing_submission.jsonl\n",
      "2014-12-25 00:00:00\n",
      "2014-12-26 00:00:00\n",
      "2014-12-27 00:00:00\n",
      "2014-12-28 00:00:00\n",
      "2014-12-29 00:00:00\n",
      "2014-12-30 00:00:00\n",
      "2014-12-31 00:00:00\n",
      "2015-12-25 00:00:00\n",
      "2015-12-26 00:00:00\n",
      "2015-12-27 00:00:00\n",
      "2015-12-28 00:00:00\n",
      "2015-12-29 00:00:00\n",
      "2015-12-30 00:00:00\n",
      "2015-12-31 00:00:00\n",
      "2016-12-25 00:00:00\n",
      "2016-12-26 00:00:00\n",
      "2016-12-27 00:00:00\n",
      "2016-12-28 00:00:00\n",
      "2016-12-29 00:00:00\n",
      "2016-12-30 00:00:00\n",
      "2016-12-31 00:00:00\n",
      "2017-12-25 00:00:00\n",
      "2017-12-26 00:00:00\n",
      "2017-12-27 00:00:00\n",
      "2017-12-28 00:00:00\n",
      "2017-12-29 00:00:00\n",
      "2017-12-30 00:00:00\n",
      "2017-12-31 00:00:00\n",
      "2018-12-25 00:00:00\n",
      "2018-12-26 00:00:00\n",
      "2018-12-27 00:00:00\n",
      "2018-12-28 00:00:00\n",
      "2018-12-29 00:00:00\n",
      "2018-12-30 00:00:00\n",
      "2018-12-31 00:00:00\n",
      "2019-12-25 00:00:00\n",
      "2019-12-26 00:00:00\n",
      "2019-12-27 00:00:00\n",
      "2019-12-28 00:00:00\n",
      "2019-12-29 00:00:00\n",
      "2019-12-30 00:00:00\n",
      "2019-12-31 00:00:00\n",
      "2020-12-25 00:00:00\n",
      "data/securityanalysis_submission.jsonl\n",
      "2014-12-25 00:00:00\n",
      "2014-12-26 00:00:00\n",
      "2014-12-27 00:00:00\n",
      "2014-12-28 00:00:00\n",
      "2014-12-29 00:00:00\n",
      "2014-12-30 00:00:00\n",
      "2014-12-31 00:00:00\n",
      "2015-12-25 00:00:00\n",
      "2015-12-26 00:00:00\n",
      "2015-12-27 00:00:00\n",
      "2015-12-28 00:00:00\n",
      "2015-12-29 00:00:00\n",
      "2015-12-30 00:00:00\n",
      "2015-12-31 00:00:00\n",
      "2016-12-25 00:00:00\n",
      "2016-12-26 00:00:00\n",
      "2016-12-27 00:00:00\n",
      "2016-12-28 00:00:00\n",
      "2016-12-29 00:00:00\n",
      "2016-12-30 00:00:00\n",
      "2016-12-31 00:00:00\n",
      "2017-12-25 00:00:00\n",
      "2017-12-26 00:00:00\n",
      "2017-12-27 00:00:00\n",
      "2017-12-28 00:00:00\n",
      "2017-12-29 00:00:00\n",
      "2017-12-30 00:00:00\n",
      "2017-12-31 00:00:00\n",
      "2018-12-25 00:00:00\n",
      "2018-12-26 00:00:00\n",
      "2018-12-27 00:00:00\n",
      "2018-12-28 00:00:00\n",
      "2018-12-29 00:00:00\n",
      "2018-12-30 00:00:00\n",
      "2018-12-31 00:00:00\n",
      "2019-12-25 00:00:00\n",
      "2019-12-26 00:00:00\n",
      "2019-12-27 00:00:00\n",
      "2019-12-28 00:00:00\n",
      "2019-12-29 00:00:00\n",
      "2019-12-30 00:00:00\n",
      "2019-12-31 00:00:00\n",
      "2020-12-25 00:00:00\n"
     ]
    }
   ],
   "source": [
    "avg_t_span = timedelta(weeks=1)\n",
    "span_interval = timedelta(days=1)\n",
    "future_t_interval = timedelta(days=3)\n",
    "\n",
    "for filename in all_files:\n",
    "    if not filename.endswith(\"submission.jsonl\"):\n",
    "        continue\n",
    "\n",
    "    subreddit_path = filename.replace(\"_submission.jsonl\", \"\")\n",
    "    print(filename)\n",
    "    \n",
    "    df = pd.read_json(filename,lines=True)\n",
    "    df[\"date\"] = pd.to_datetime(df['created_utc'],unit='s')\n",
    "    \n",
    "    # clean dataset\n",
    "    df[\"ticker\"] = df[\"tickers\"].map(lambda tickers: tickers[0][0] if len(tickers) > 0 else np.NaN)\n",
    "    df = df[df[\"ticker\"].isin(ticker_list)]\n",
    "    df.dropna()\n",
    "    df.set_index(\"date\", inplace=True)\n",
    "    df.sort_index(inplace=True)\n",
    "    \n",
    "    features = []\n",
    "    \n",
    "    t = start\n",
    "    while t <= end - avg_t_span:\n",
    "#         mask = (df >= t) & (df <= t + avg_t_span)\n",
    "#         submissions = df.loc[mask]\n",
    "#         print(df.index)\n",
    "#         print(t)\n",
    "        if(t.year != (t + avg_t_span).year):\n",
    "            print(t)\n",
    "\n",
    "        grouped_submissions = df[str(t):str(t+avg_t_span)]\n",
    "        if len(grouped_submissions) == 0:\n",
    "            t += span_interval\n",
    "            continue\n",
    "        \n",
    "        comment_mask = comment_sentiments[\"submission_name\"].isin(submissions[\"name\"])\n",
    "        comment_mask = comment_mask & comment_sentiments[\"ticker\"].isin(ticker_list)\n",
    "        grouped_comments = comment_sentiments.loc[comment_mask]\n",
    "        \n",
    "        for ticker in ticker_list:\n",
    "            submissions = grouped_submissions[grouped_submissions[\"ticker\"] == ticker]\n",
    "            if len(submissions) == 0:\n",
    "                continue\n",
    "            \n",
    "            comment_mask = grouped_comments[\"submission_name\"].isin(submissions[\"name\"])\n",
    "            comment_mask = comment_mask & (grouped_comments[\"ticker\"] == ticker)\n",
    "            comments = grouped_comments.loc[comment_mask]\n",
    "            \n",
    "            s_scores = submissions[\"score\"].values\n",
    "            s_uv_ratio = submissions[\"upvote_ratio\"].values\n",
    "\n",
    "            s_sentiments = submission_sentiments.loc[submissions[\"name\"],[\"neg\",\"neu\",\"pos\"]].values\n",
    "            s_sentiments *= (s_scores * s_uv_ratio).reshape(-1,1)\n",
    "            s_sentiments = s_sentiments.sum(axis=0)\n",
    "\n",
    "            if len(comments) == 0:\n",
    "                c_sentiments = np.zeros(3)\n",
    "            else:\n",
    "                c_sentiments = comments[[\"neg\",\"neu\",\"pos\"]].values\n",
    "                c_scores = comments[\"score\"].values\n",
    "                c_sentiments = (c_sentiments * c_scores.reshape(-1,1)).sum(axis=0)\n",
    "                \n",
    "            # Get Stock Stuff\n",
    "            stock = stock_data[ticker]\n",
    "            cur_stock_idx = stock.index.get_loc(t, method=\"nearest\")\n",
    "            future_stock_idx = stock.index.get_loc(t + avg_t_span, method=\"nearest\")\n",
    "            cur_stock = stock.iloc[cur_stock_idx][\"Open\"] #Note : is rounded to nearest date\n",
    "            future_stock = stock.iloc[future_stock_idx][\"Close\"]\n",
    "            \n",
    "            label = 1 if cur_stock <= future_stock else 0\n",
    "            \n",
    "            feature_vector = np.concatenate((s_sentiments, c_sentiments, np.array([label])), axis=0)\n",
    "            features.append(feature_vector)\n",
    "        \n",
    "        t += span_interval\n",
    "    pd.DataFrame(np.array(features)).to_csv(f\"{subreddit_path}_features_labels.csv\", index=False)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-metadata",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
